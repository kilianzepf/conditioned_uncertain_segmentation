import os
from tqdm import tqdm
import argparse
from types import SimpleNamespace
from datetime import datetime

import torch
from torch._C import device
import torch.nn as nn

# Import own files
from metadata_manager import *
from utils.utils import *
from utils.metrics import *
from models.prob_unet import *
from dataloaders import *


parser = argparse.ArgumentParser()
parser.add_argument(
    "--what",
    default="isic3_style_concat",
    help="Dataset to train on.",
)
parser.add_argument(
    "--lr",
    default=0.0001,
    type=float,
    help="Learning Rate for Training. Default is 0.0001",
)
parser.add_argument(
    "--epochs", default=200, type=int, help="Number of Epochs to train. Default is 200"
)
parser.add_argument(
    "--batchsize", default=6, type=int, help="Number of Samples per Batch. Default is 6"
)
parser.add_argument(
    "--weightdecay",
    default=0,
    type=float,
    help="Parameter for Weight Decay. Default is 0",
)
parser.add_argument(
    "--resume_epoch",
    default=0,
    type=int,
    help="Resume training at the specified epoch. Default is 0",
)
parser.add_argument(
    "--save_model",
    default=False,
    type=bool,
    help="Set True if checkpoints should be saved. Default is False",
)
parser.add_argument(
    "--testit",
    default=False,
    type=bool,
    help="Set True testing the trained model on the testset. Default is False",
)
parser.add_argument(
    "--test_treshold",
    default=0.5,
    type=float,
    help="Treshold for masking the logid/sigmoid predictions. Only use with --testit. Default is 0.5",
)
parser.add_argument(
    "--N", default=16, type=int, help="Number of Samples for GED Metric. Default is 16"
)
parser.add_argument(
    "--W",
    default=1,
    type=int,
    help="Set 0 to turn off Weights and Biases. Default is 1 (tracking)",
)
parser.add_argument(
    "--transfer",
    default="None",
    help="Activates transfer learning when given a model's name. Default is None (no transfer learning)",
)
parser.add_argument(
    "--num_filters",
    default=[32, 64, 128, 192],
    nargs="+",
    help="Number of filters per layer. Default is [32,64,128,192]",
    type=int,
)
parser.add_argument(
    "--beta", default=10.0, type=float, help="Beta for ELBO calculation . Default is 10"
)


def train(
    model,
    resume_epoch,
    epochs,
    opt,
    train_loader,
    val_loader,
    save_checkpoints,
    transfer_model,
    metadata,
    forward_passes,
    W=True,
):
    # Set device to Cuda if GPU is available
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Check if want to resume prior checkpoints
    if resume_epoch > 0:
        print(f"Resuming training on epoch {resume_epoch} ... \n")
        # Load Checkpoint
        checkpoint = torch.load(
            f"checkpoints/{meta.directory_name}/{model.name}/{resume_epoch}_checkpoint.pt"
        )
        # Inject checkpoint to model and optimizer
        model.load_state_dict(checkpoint["model_state_dict"])
        opt.load_state_dict(checkpoint["optimizer_state_dict"])
        epoch = checkpoint["epoch"]
        loss = checkpoint["loss"]
    if transfer_model != "None":
        print(f"Continue Training on the model {transfer_model}...\n")
        transfer_dict = torch.load(
            f"saved_models/{meta.directory_name}/{transfer_model}.pt"
        )
        model = transfer_dict["model"]
        opt = transfer_dict["optimizer"]
        loss = transfer_dict["loss"]
    else:
        print(f"Training from scratch...\n")

    # Log model to wandb
    if W:
        wandb.watch(model, log_freq=100)

    for epoch in tqdm(range(resume_epoch, epochs)):  # may be error in range
        sum_batch_loss = 0
        sum_batch_IoU = 0
        counter = 0
        model.train()
        for images, masks, _, style in train_loader:
            counter += 1
            # Send tensors to Cuda
            images = images.to(device)
            masks = masks.to(device)

            model.forward(images, masks, training=True)
            # Calculate the Elbo
            elbo = model.elbo(masks)

            # Get the prediction used for reconstruction loss (generated by a z from the distribution parametrized by the current posterior net)
            logits = model.reconstruction  # these are logits
            # Treshold to get a binary prediction
            pred_mask = torch.sigmoid(logits).ge(meta.masking_threshold)
            # This is L2 regularization/weight decay
            reg_loss = (
                l2_regularisation(model.posterior)
                + l2_regularisation(model.prior)
                + l2_regularisation(model.fcomb.layers)
            )
            loss = -elbo + 1e-5 * reg_loss
            # Set parameter gradients to None
            opt.zero_grad(set_to_none=True)
            # Backward pass & weight update
            loss.backward()
            opt.step()

            # Calculate Average Loss and IoU
            sum_batch_loss += loss
            batch_IoU = IoU(masks, pred_mask)
            sum_batch_IoU += batch_IoU

            # Log images, targets and predictions to wandb every 5 epochs
            if (epoch % 50 == 0) and (counter == 1):
                grid = make_image_grid(
                    images, masks, torch.sigmoid(logits), required_padding=(0, 0, 0, 0)
                )
                if W:
                    wandb.log(
                        {
                            "Images during Training": [
                                wandb.Image(
                                    grid,
                                    caption="Images, Targets, Prediction used for Elbo calculation",
                                )
                            ]
                        },
                        step=epoch,
                    )

        # Log the average loss of all batches in the epoch to Wandb
        if W:
            wandb.log(
                {
                    "Average Loss per Epoch while Training": sum_batch_loss
                    / (len(train_loader)),
                    "Average IoU per Epoch while Training": sum_batch_IoU
                    / (len(train_loader)),
                },
                step=epoch,
            )

        if save_checkpoints == True:
            os.makedirs(
                f"checkpoints/{meta.directory_name}/{model.name}", exist_ok=True
            )
            torch.save(
                {
                    "epoch": epoch + 1,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": opt.state_dict(),
                    "loss": loss,
                },
                f"checkpoints/{meta.directory_name}/{model.name}/{epoch+1}_checkpoint.pt",
            )

        # Save the model after last training epoch (for inference or transfer training) to a folder
        if epoch == epochs - 1:
            os.makedirs(f"saved_models/{meta.directory_name}", exist_ok=True)
            torch.save(
                {"model": model, "optimizer": opt, "loss": loss},
                f"saved_models/{meta.directory_name}/{model.name}.pt",
            )

        """
        Evaluate on the validation set and track to see if overfitting happens
        """

        sum_IoU = 0
        sum_loss = 0
        counter = 0
        model.eval()
        with torch.no_grad():
            for images, masks, seg_dist, style in val_loader:
                counter += 1
                # Send tensors to Cuda
                images = images.to(device)
                masks = masks.to(device)
                seg_dist = [x.to(device) for x in seg_dist]

                # IoU/Loss on Image Level
                model.forward(images, masks, training=False)  # outputs logits
                logits = model.sample(testing=True)
                pred_mask = (torch.sigmoid(logits)).ge(meta.masking_threshold)
                # Calculate Loss
                loss_function = nn.BCEWithLogitsLoss()
                sum_IoU += IoU(masks, pred_mask)
                sum_loss += loss_function(logits, masks)

                # Log images, targets and predictions of the first batch to wandb every 50 epochs
                if (epoch % 50 == 0) and (counter == 2):
                    grid = make_image_grid(
                        images,
                        masks,
                        torch.sigmoid(logits),
                        required_padding=(0, 0, 0, 0),
                    )
                    if W:
                        wandb.log(
                            {
                                "Images during Validation": [
                                    wandb.Image(
                                        grid, caption="Images, Targets, Predictions"
                                    )
                                ]
                            },
                            step=epoch,
                        )

        if W:
            wandb.log(
                {
                    "Loss on Validation Set (post Epoch)": sum_loss / len(val_loader),
                    "IoU on Validation Set (post Epoch)": sum_IoU / len(val_loader),
                },
                step=epoch,
            )


if __name__ == "__main__":
    # Load parsed arguments from command lind
    args = parser.parse_args()

    what_task = args.what
    resume_epoch = args.resume_epoch
    epochs = args.epochs
    batch_size = args.batchsize
    learning_rate = args.lr
    weight_decay = args.weightdecay
    save_checkpoints = args.save_model
    forward_passes = args.N
    W = bool(args.W)  # Bool for turning off wandb tracking
    transfer_model = args.transfer
    num_filters = args.num_filters
    beta = args.beta

    if W:
        import wandb

        wandb.login()

    # Read in Metadata for the task chosen in command line
    """
    Example:
    Available meta data (example is kidney)
            'description': '            Kidney dataset from Qubiq21',
            'training_data_path':       'data/data_qubiq/training_data_v3_QC/kidney/Training',
            'validation_data_path':     'data/data_qubiq/training_data_v3_QC/kidney/Training',
            'test_data_path':           None,
            'masking_threshold':        0.5,
            'image_size':               497,
            'admissible_size':          572,
            'output_size':              484,
            'directory_name':           'kidney'
    """
    meta_dict = get_meta(what_task)
    meta = SimpleNamespace(**meta_dict)

    # Hand some information about the current run to Wandb
    config = dict(
        epochs=epochs,
        resumed_at=resume_epoch,
        batch_size=batch_size,
        learning_rate=learning_rate,
        weight_decay=weight_decay,
        loss="(Elbo) Reconstruction Loss: BCEWithLogitsLoss / KL",
        architecture="Probabilistic U-Net",
        dataset=meta.description,
        N_for_metrics=forward_passes,
        filters=num_filters,
    )

    if W:
        # Create the Training Run in Wandb
        wandb.init(
            project="Style ProbUnet",
            group="Probabilistic Unets",
            job_type="Training",
            config=config,
            dir="/scratch/kmze",
        )
        training_run_name = wandb.run.name
    else:
        # Use current timestamp as name e.g. 2021_12_11_14_46
        training_run_name = (
            str(datetime.now())[:16]
            .replace(" ", "_")
            .replace("-", "_")
            .replace(":", "_")
        )

    print(f"Modelname: {training_run_name}")
    # Check for GPU
    if torch.cuda.is_available():
        print("\nThe model will be run on GPU.")
    else:
        print("\nNo GPU available!")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nUsing the {meta.description} dataset.\n")

    # Set the random seed for reproducible experiments
    torch.manual_seed(230)
    if device == "cuda":
        torch.cuda.manual_seed(230)

    # Initialize Probabilistic U-Net
    prob_unet = ProbabilisticUnet(
        name=training_run_name,
        input_channels=meta.channels,
        num_classes=1,
        num_filters=num_filters,
        latent_dim=6,
        no_convs_fcomb=4,
        beta=beta,
    ).to(device)

    # Count number of total parameters in the model and log
    pytorch_total_params = sum(p.numel() for p in prob_unet.parameters())
    if W:
        wandb.run.summary["Total Model Parameters"] = pytorch_total_params

    # Note that Weight Decay and L2 Regularization are not the same (except for SGD) see paper: Hutter 2019 'Decoupled Weight Decay Regularization'
    # AdamW implements the correct weight decay as shown in their paper
    # Also Note: We use L2 regularization terms within the loss function for weight decay in the Encoders
    opt = torch.optim.AdamW(
        prob_unet.parameters(), lr=learning_rate, weight_decay=weight_decay
    )

    # Fetch Dataloaders
    train_loader, _ = get_dataloader(
        task=what_task, split="train", batch_size=batch_size, shuffle=True
    )
    val_loader, _ = get_dataloader(
        task=what_task, split="val", batch_size=4, shuffle=False
    )

    # Empty GPU Cache
    torch.cuda.empty_cache()
    # Start Training
    train(
        prob_unet,
        resume_epoch,
        epochs,
        opt,
        train_loader,
        val_loader,
        save_checkpoints,
        transfer_model,
        meta,
        forward_passes,
        W=W,
    )
    print(f"Saved: {training_run_name} Data: {what_task} Model: Prob. U-Net")
    # End Training Run
    if W:
        wandb.finish
